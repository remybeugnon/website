install.packages('easyPubMed')
library('scholar')
library('easyPubMed')
install.packages('scholar')
install.packages('easyPubMed')
library('scholar')
library('easyPubMed')
scholar.id = "fEd4WGYAAAAJ"
pub = get_publications(scholar.id)
pub
blogdown::stop_server()
blogdown::serve_site()
pub$title[1]
title = pub$title[1]
my_request <- get_pubmed_ids_by_fulltitle(title, field = "[Title]")
my_request
my_xml <- fetch_pubmed_data(my_request)
my_xml
my_xml <- fetch_pubmed_data(my_request)
head(my_xml)
my_xml <- fetch_pubmed_data(my_request)
substr(my_xml, start = 1, stop = 100)
my_xml <- fetch_pubmed_data(my_request)
substr(my_xml, start = 1, stop = 500)
custom_grep(my_xml, tag = "Affiliation") %>% unlist
libs <- c(
'dplyr',
'ggplot2',
'scholar',
'easyPubMed'
)
invisible(lapply(libs, library, character.only = T))
custom_grep(my_xml, tag = "Affiliation") %>% unlist
my_xml
affiliations = data.frame(matrix(NA, ncol = 2, nrow = 1))
colnames(affiliations) = c('title', 'affiliation')
for(j in 1 : length(pub$title)){
skip_to_next <- FALSE
tryCatch( # I use tryCatch to catch the papers not found on PubMed
{
my_entrez_id <- get_pubmed_ids_by_fulltitle(pub$title[j], field = "[Title]")
my_xml <- fetch_pubmed_data(my_entrez_id)
affiliation =
affiliations = bind_rows(
affiliations,
data.frame(
title = pub$title[j],
affiliation = custom_grep(my_xml, tag = "Affiliation") %>% unlist
)
)
}, error = function(e){
skip_to_next <<- TRUE
}
)
if(skip_to_next) {
affiliations = bind_rows(
affiliations,
data.frame(
title = pub$title[j],
affiliation = "NOT FOUND")
)
next }  # To continue the script in the next occurence
}
affiliations
library(maps)
head(world.cities)
grepl(pattern = world.cities$name[1], x = affiliations$affiliation,fixed = T)
grepl(pattern = world.cities$name[1], x = affiliations$affiliation,fixed = T) %>% sum()
grepl(pattern = world.cities$name[1], x = affiliations$affiliation, fixed = T)
lapply(world.cities$name, function(x) {grepl(pattern = x, x = affiliations$affiliation, fixed = T) %>% sum()})
lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[1],
fixed = T)})
grepl(pattern = x,
x = affiliations$affiliation[1],
fixed = T)}) %>% unlist
lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[1],
fixed = T)}) %>% unlist
world.cities$name [lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[1],
fixed = T)}) %>% unlist]
world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[1],
fixed = T)}) %>% unlist]
affiliations$affiliation[1]
affiliations
world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[2],
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[2],
fixed = T)}) %>% unlist]
country
world.cities %>% filter(name %in% city & country.etc %in% country)
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[2],
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = affiliations$affiliation[2],
fixed = T)}) %>% unlist]
world.cities %>% filter(name %in% city & country.etc %in% country)
world.cities %>%
filter(name %in% city & country.etc %in% country) %>%
select(City = name, Country = country.etc, lat, long)
world.cities %>%
filter(name %in% city & country.etc %in% country) %>%
select(City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City))
c =
world.cities %>%
mutate(Affiliation = affiliations$affiliation[2])
c
c =
world.cities %>%
mutate(Affiliation = affiliations$affiliation[2]) %>%
filter(name %in% city & country.etc %in% country) %>%
select(Affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
c
colnames(df.cities) = c('Affiliation', 'City', 'Country', 'lat', 'long')
# New dataset
df.cities = data.frame(matrix(NA, ncol = 5, nrow = 0))
colnames(df.cities) = c('Affiliation', 'City', 'Country', 'lat', 'long')
# New dataset
df.cities = data.frame(matrix(NA, ncol = 5, nrow = 0))
for(af in unique(affiliations$affiliation)){
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
c =
world.cities %>%
mutate(Affiliation = af) %>%
filter(name %in% city & country.etc %in% country) %>%
select(Affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
df.cities = bind_rows(
df.cities,
c
)
}
df.cities
# New dataset
df.cities = data.frame(matrix(NA, ncol = 5, nrow = 0))
colnames(df.cities) = c('Affiliation', 'City', 'Country', 'lat', 'long')
for(af in unique(affiliations$affiliation)){
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
c =
world.cities %>%
mutate(Affiliation = af) %>%
filter(name %in% city & country.etc %in% country) %>%
select(Affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
df.cities = bind_rows(
df.cities,
c
)
}
# New dataset
df.cities = data.frame(matrix(NA, ncol = 5, nrow = 1))
colnames(df.cities) = c('Affiliation', 'City', 'Country', 'lat', 'long')
for(af in unique(affiliations$affiliation)){
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
c =
world.cities %>%
mutate(Affiliation = af) %>%
filter(name %in% city & country.etc %in% country) %>%
select(Affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
df.cities = bind_rows(
df.cities,
c
)
}
df.cities
affiliations = left_join(affiliations, df.cities, by = "affiliation")
# New dataset
df.cities = data.frame(matrix(NA, ncol = 5, nrow = 1))
colnames(df.cities) = c('affiliation', 'City', 'Country', 'lat', 'long')
for(af in unique(affiliations$affiliation)){
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
c =
world.cities %>%
mutate(affiliation = af) %>%
filter(name %in% city & country.etc %in% country) %>%
select(affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
df.cities = bind_rows(
df.cities,
c
)
}
for(af in unique(affiliations$affiliation)){
city = world.cities$name[lapply(world.cities$name, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
country = world.cities$country.etc[lapply(world.cities$country.etc, function(x) {
grepl(pattern = x,
x = af,
fixed = T)}) %>% unlist]
c =
world.cities %>%
mutate(affiliation = af) %>%
filter(name %in% city & country.etc %in% country) %>%
select(affiliation, City = name, Country = country.etc, lat, long) %>%
filter(!duplicated(City)) # To remove multiple entries
df.cities = bind_rows(
df.cities,
c
)
}
affiliations = left_join(affiliations, df.cities, by = "affiliation")
affiliations
affiliations
library("tm")
library("SnowballC")
library("wordcloud")
library("wordcloud2")
list.stop = c('affect', 'effects', 'using')
docs <- Corpus(VectorSource(pub$title))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- docs %>%
tm_map(., toSpace, "/") %>%
tm_map(., toSpace, "@") %>%
tm_map(., toSpace, "\\|") %>%
tm_map(., content_transformer(tolower)) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, stopwords("english")) %>%
tm_map(., removeWords, list.stop) %>%
tm_map(., removePunctuation) %>%
tm_map(., stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
col.pal = colorRampPalette(colors = c('Darkbrown','Darkgreen'))
col.pal = colorRampPalette(colors = c('brown','Darkgreen'))
wordcloud2(data=d, size=1, color=col.pal(10))
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(rworldmap)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(ggspatial)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(sf)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(rnaturalearth)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(rnaturalearthdata)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(maps)
ggplot(data = world) +
geom_sf(fill = world$fill, alpha = world$alpha) +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
library(maps)
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 10,
color = "blue") +
labs(x = '', y = '')
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
shape = 1,
color = "blue") +
labs(x = '', y = '')
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
fill = "blue") +
labs(x = '', y = '')
color = 'red
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
color = 'red'
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 5,
color = 'red',
fill = "blue") +
labs(x = '', y = '')
blogdown::serve_site()
blogdown:::preview_site()
libs <- c(
'dplyr',
'ggplot2',
'scholar',
'easyPubMed'
)
invisible(lapply(libs, library, character.only = T))
affiliations = data.frame(matrix(NA, ncol = 2, nrow = 1))
colnames(affiliations) = c('title', 'affiliation')
for(j in 1 : length(pub$title)){
skip_to_next <- FALSE
tryCatch( # I use tryCatch to catch the papers not found on PubMed
{
my_entrez_id <- get_pubmed_ids_by_fulltitle(pub$title[j], field = "[Title]")
my_xml <- fetch_pubmed_data(my_entrez_id)
affiliations = bind_rows(
affiliations,
data.frame(
title = pub$title[j],
affiliation = custom_grep(my_xml, tag = "Affiliation") %>% unlist
)
)
}, error = function(e){
skip_to_next <<- TRUE
}
)
if(skip_to_next) {
affiliations = bind_rows(
affiliations,
data.frame(
title = pub$title[j],
affiliation = "NOT FOUND")
)
next }  # To continue the script in the next occurrence
}
View(affiliations)
save(affiliations, file = "affiliation.RData")
blogdown:::preview_site()
scholar.id2 = "OV0sKRkAAAAJ"
pub2 = get_publications(scholar.id2)
docs <- Corpus(VectorSource(pub2$title))
library("tm")
library("SnowballC")
library("wordcloud2")
# List of words to remove
list.stop = c('affect', 'effects', 'using')
docs <- Corpus(VectorSource(pub$title))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- docs %>%
tm_map(., toSpace, "/") %>%
tm_map(., toSpace, "@") %>%
tm_map(., toSpace, "\\|") %>%
tm_map(., content_transformer(tolower)) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, stopwords("english")) %>%
tm_map(., removeWords, list.stop) %>%
tm_map(., removePunctuation) %>%
tm_map(., stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
col.pal = colorRampPalette(colors = c('brown','Darkgreen'))
wordcloud2(data = d,
size = 1,
color = col.pal(10))
scholar.id2 = "OV0sKRkAAAAJ"
pub2 = get_publications(scholar.id2)
docs <- Corpus(VectorSource(pub2$title))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- docs %>%
tm_map(., toSpace, "/") %>%
tm_map(., toSpace, "@") %>%
tm_map(., toSpace, "\\|") %>%
tm_map(., content_transformer(tolower)) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, stopwords("english")) %>%
tm_map(., removeWords, list.stop) %>%
tm_map(., removePunctuation) %>%
tm_map(., stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
col.pal = colorRampPalette(colors = c('brown','Darkgreen'))
wordcloud2(data = d,
size = 1,
color = col.pal(10))
ggplot(data =  ne_countries(scale = "medium", returnclass = "sf")) +
geom_sf() +
geom_point(data = affiliations,
aes(x = long, y = lat),
size = 2,
color = 'red',
fill = "blue") +
labs(x = '', y = '')
pub
pub %>%
data.frame() %>%
select(Title = title, Authors = author,
Journal = journal, `Vol(Issue),page`,
Year = year) %>%
kableExtra::kable()
pub %>%
data.frame() %>%
select(Title = title, Authors = author,
Journal = journal, `Vol(Issue),page` = number,
Year = year) %>%
kableExtra::kable()
scholar.id2 = "OV0sKRkAAAAJ"
pub2 = get_publications(scholar.id2)
docs <- Corpus(VectorSource(pub2$title))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- docs %>%
tm_map(., toSpace, "/") %>%
tm_map(., toSpace, "@") %>%
tm_map(., toSpace, "\\|") %>%
tm_map(., content_transformer(tolower)) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, stopwords("english")) %>%
tm_map(., removeWords, list.stop) %>%
tm_map(., removePunctuation) %>%
tm_map(., stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
col.pal = colorRampPalette(colors = c('brown','Darkgreen'))
wordcloud2(data = d,
size = 1,
color = col.pal(10))
